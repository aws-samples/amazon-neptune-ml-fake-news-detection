{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f98bd3b-d27e-4266-914b-0b4616d2c7a9",
   "metadata": {},
   "source": [
    "# Inductive Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8dbb93c-ca2a-476f-a57d-1a9e825ed4e9",
   "metadata": {},
   "source": [
    "In this notebook, we go through an example of real-time inductive inference with Amazon Neptune ML. Inductive inference allows customers to enable machine learning (ML) predictions on nodes, edges and properties (entities) that were added to the graph after the ML model training process.\n",
    "\n",
    "Specifically, we will be doing inductive inference on an unseen news node that we will add to the database. We will also add an edge between the new news node and an existing user node to show that the news was spread by the specified user."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b2b9fb-c041-48c8-bc22-06985628f758",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f9a4c1-a42e-480e-bc38-11f9f2e7dbad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "import boto3\n",
    "import sagemaker\n",
    "import pandas as pd\n",
    "import utils.neptune_ml_utils as neptune_ml\n",
    "# Check to make sure your Neptune cluster is configured to run Neptune ML.\n",
    "neptune_ml.check_ml_enabled()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0772ad2-5027-46bd-8826-46b1059a46b1",
   "metadata": {},
   "source": [
    "### Understanding the existing graph data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd9c0ca-f904-42ce-8ef3-5cc883a5bc65",
   "metadata": {},
   "source": [
    "First, let's check the status of the Neptune database to ensure it is healthy before we begin making gremlin queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45616a02-2f9c-43e6-8c9b-b50ea0097e09",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%status"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7366c782-cf7d-44e8-87a1-efbf87ae96f5",
   "metadata": {},
   "source": [
    "#### Overview of nodes and edges\n",
    "Let's take a look at the nodes andd edges, each counted by type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16869b8b-05d8-498d-ab8d-b6c8141cfb03",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%gremlin\n",
    "g.V().groupCount().by(label).unfold().order().by(keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ba7481-033e-47a0-9771-c52fbab41c5a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%gremlin\n",
    "g.E().groupCount().by(label).unfold().order().by(keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be00657b-ece3-4b9f-a330-587fe999918f",
   "metadata": {},
   "source": [
    "We can see that we have the same number of nodes and edges we saw in the previous notebooks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee8142c-9c93-4e16-8fab-58f8d8ba88fe",
   "metadata": {},
   "source": [
    "## View the existing user\n",
    "Since we are going to connect the news node to a user node, let's select a user that will serve as the vertex for the edge we create. This means the news will be spread by this user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf70a43-ace6-40a3-8f58-1dea185085c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%gremlin\n",
    "g.V().hasLabel('user')\n",
    "        .elementMap().limit(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9775b1f0-6977-45a9-82a6-c143144eb86a",
   "metadata": {},
   "source": [
    "We can see that the users contain a lot of features. Let's take a look at user_1 to keep things simple for the example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa73229-0d91-4b60-be6b-b2688f533b97",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%gremlin\n",
    "\n",
    "g.V().hasLabel(\"user\").hasId(\"user_1\")\n",
    "        .elementMap()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd26a74-8ee9-4c44-89f6-5a6c288bb4a6",
   "metadata": {},
   "source": [
    "## Create the unseen news node and edge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b93b0ce-5bd7-488b-8568-f88438ec8ba4",
   "metadata": {},
   "source": [
    "First, let's define the news title. We can make it whatever we want. In reality, this would be the unseen news title you want to add to the database. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c304857-8f1f-4f44-80ec-07db2ef046fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "news_title_str = \"This is dummy news title used for the inductive inference!\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c994bb-88c8-4ca1-8b9f-0920435c6072",
   "metadata": {},
   "source": [
    "Now, let's add a node with this news title and create a `spread_by` edge connecting it to user_1. Note that we gave pseudo names of `node_1` and `node_2` to the news and the user, respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc367fd5-0177-4ec2-97c7-c984bd4182ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%gremlin\n",
    "g.addV('news').\n",
    "    property('news_title','${news_title_str}')\n",
    "    .as('node_1')\n",
    "    .V().hasLabel(\"user\")\n",
    "        .hasId(\"user_1\")\n",
    "    .as('node_2')\n",
    "    .addE('spread_by').from('node_1').to('node_2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44024ad-c925-40e4-be57-04aba762b9ab",
   "metadata": {},
   "source": [
    "##### Verify Successful Node Creation\n",
    "Run the code below and click the graph tab. You should see a news node spread by a user node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0a7886-857f-4e48-9a53-04ba34200e98",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%gremlin -p v,oute,inv\n",
    "\n",
    "g.V().hasLabel('news')\n",
    "    .has('news_title','${news_title_str}')\n",
    "    .outE().inV().path()\n",
    "    .by(elementMap())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c1d5450-0b6c-4bc7-aee5-a0f98958981c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Inference\n",
    "Now that we have our unseen news node and relevant edges added, let's perform inference to get the node classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335e6900-7267-428a-9442-6c3a822e10b8",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Define endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d89efef6-a4a2-42c1-8e15-97f29ebd729e",
   "metadata": {},
   "source": [
    "First, let's define the name of our endpoint so that we can use it to make the prediction. If you have previously run the detect-fake-news notebook without restarting the kernel, you should be able to retrieve the endpoint using the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8574c06-46a1-4e3c-906f-f51692ecbb88",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture captured_output \n",
    "%store -r endpoint "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084343df-5afb-43ff-a50c-498a58594f01",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown\n",
    "if 'no stored variable or alias' in captured_output.stdout:\n",
    "    display(Markdown(\"Looks like you don't have the endpoint variable, so you'll need to follow the steps below to get your endpoint name: \\n\\n 1. Open the [SageMaker console](https://console.aws.amazon.com/sagemaker/)   \\n  2. Select **Inference** in the left hand panel   \\n  3. Click on **Endpoints**  \\n   4. Copy the name of the endpoint that you want to invoke \\n\\n Once you have the name of the endpoint, change it in the line below:\"))\n",
    "else:\n",
    "    print(\"successfully loaded the endpoint name. No action required - continue running the cells.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d3ff9e-3cbd-47a4-ada3-7874797bee20",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if \"endpoint\" not in locals():\n",
    "    endpoint = \"yourEndpointNameHereIfNotAlreadyDefined\" # only required if above cell outputs instructions to find it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ddc4a0-1b19-4be7-a147-bf01f31df946",
   "metadata": {},
   "source": [
    "### Transductive and Inductive Inference\n",
    "Information on each type of inference is described in the corresponding sections below. Click [here](https://docs.aws.amazon.com/neptune/latest/userguide/machine-learning-overview.html) for a detailed overview about these two types of inference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8efda35-dff9-4d4a-9176-bd4bd4211815",
   "metadata": {},
   "source": [
    "#### Transductive inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c32172f-4d7b-4837-91e5-19e2b9590273",
   "metadata": {},
   "source": [
    "When performing transductive inference, Neptune looks up and returns predictions that were pre-computed at the time of training.\n",
    "\n",
    "The below scenario involves transductive inference, and it is important to note that the newly created node was not present during the Neptune ML model training in previous notebook. Consequently, the expected outcome of this situation is a blank output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24f2051-064a-4fbc-aed1-1e028a4fa63d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%gremlin \n",
    "g.with(\"Neptune#ml.endpoint\", \"${endpoint}\")\n",
    "    .V().has('news_title', \"${news_title_str}\")\n",
    "    .properties(\"news_type\",\"Neptune#ml.score\")\n",
    "    .with(\"Neptune#ml.classification\")\n",
    "    .value()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84efa61e-f90d-4443-a057-9f8e0e418f81",
   "metadata": {},
   "source": [
    "#### Inductive Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc57cea3-229f-43db-b940-3db2df57f1d4",
   "metadata": {
    "tags": []
   },
   "source": [
    "In below scenario, we are explicitly employing inductive inference on the new node we created (and the relevant information / edges) using the endpoint specified. Therefore, we will be making predictions on data that was not part of the Neptune ML model training process. As a result, the cell will produce an output along with a confidence score to indicate the level of certainty in the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa02e56a-12a9-45dd-b0a5-e72b09f9bd9c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%gremlin\n",
    "g.with(\"Neptune#ml.endpoint\", \"${endpoint}\").\n",
    "    V().hasLabel(\"news\").\n",
    "    has('news_title', '${news_title_str}').\n",
    "    properties(\"news_type\",  \"Neptune#ml.score\").\n",
    "    with(\"Neptune#ml.inductiveInference\").\n",
    "    with(\"Neptune#ml.classification\").value()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e5c8bf-fddf-4ba8-b6c7-1d581496771b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f1cd0719-55da-48bb-93b8-fa9efb7a8229",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Inductive inference with minimum 60% confidance\n",
    "Now let's add a confidence threshold of 60%. This means we are only using the values that have 60% confidence or highter for comparison to do the classification. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b0b348-e762-4147-98b3-5a64bfc7cdad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%gremlin\n",
    "g.with(\"Neptune#ml.endpoint\", \"${endpoint}\").\n",
    "    V().hasLabel(\"news\").\n",
    "    has('news_title', '${news_title_str}').\n",
    "    properties(\"news_type\",  \"Neptune#ml.score\").\n",
    "    with(\"Neptune#ml.inductiveInference\").\n",
    "    with(\"Neptune#ml.threshold\", 0.6D).\n",
    "    with(\"Neptune#ml.classification\").value()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb03afef-ba58-4441-a84a-0f4bb1a26831",
   "metadata": {},
   "source": [
    "## Cleaning Up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e9b472-55e1-4ff7-a87d-12823386c42d",
   "metadata": {},
   "source": [
    "Now that we can delete the inference endpoint to avoid recurring costs!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2861bb-2ba3-4947-b594-7b97ebe0516a",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### first get training_job_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "028f6894-4983-443f-a111-c832fbbae74c",
   "metadata": {},
   "source": [
    "First, let's define the name of our training_job_name so that we can use it to make the prediction. If you have previously run the detect-fake-news notebook without restarting the kernel, you should be able to retrieve the endpoint using the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963b801d-9336-47e3-9a76-2f0c6a2f51d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture captured_output_training_job\n",
    "%store -r training_job_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c39bea0-6cbd-4805-9e95-934b5227aa06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown\n",
    "if 'no stored variable or alias' in captured_output_training_job.stdout:\n",
    "    display(Markdown(\"Looks like you don't have the training job name variable, so you'll need to follow the steps below to get your endpoint name: \\n\\n 1. Open the [SageMaker console](https://console.aws.amazon.com/sagemaker/)   \\n 2. Select **Training** in the left hand panel   \\n 3. Click on **Training Jobs**  \\n 4. Copy the name of the training job you created. \\n\\n Once you have the name of the training job, change it in the line below:\"))\n",
    "else:\n",
    "    print(\"successfully loaded the endpoint name. No action required - continue running the cells.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f42a07-cfba-4d87-9a62-c06df0dca633",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if \"training_job_name\" not in locals():\n",
    "    training_job_name = \"yourTrainingJobNameHereIfNotAlreadyDefined\" # only required if above cell outputs instructions to find it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "803fd6d9-e2f8-464d-ac22-d1a15f22e5fc",
   "metadata": {},
   "source": [
    "#### now delete the endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ee94a7-9b71-4927-ba17-80b76178ccce",
   "metadata": {},
   "outputs": [],
   "source": [
    "neptune_ml.delete_endpoint(training_job_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24e2ab3-ecdf-44ff-8f78-c9aae269e7f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
